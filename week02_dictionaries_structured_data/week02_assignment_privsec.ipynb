{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 02 ‚Äî Extracting Structure: Headings, Sections, and ‚ÄúChoice‚Äù Cues\n",
        "\n",
        "**Time budget:** ~2 hours  \n",
        "**Goal:** Extract headings/sections and detect UX-relevant cues (choices, opt-out, consent, retention).\n",
        "\n",
        "**Theme (PhD focus):** Human factors of privacy & security ‚Äî scraping public pages (privacy policies, cookie notices, security help pages, standards/regulator guidance) and extracting *UX-relevant* signals.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverables\n",
        "- A completed notebook with working code\n",
        "- A dataset variable (`rows` or `df`) saved to disk (CSV/JSON depending on week)\n",
        "- 3‚Äì5 bullet reflection grounded in human factors/privacy-security research\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Responsible scraping note (important)\n",
        "We will only scrape **public pages** and keep the volume small.\n",
        "- Prefer a few pages, not thousands\n",
        "- Respect robots.txt/Terms of Service when you scale later\n",
        "- Avoid collecting personal data\n",
        "- Add delays for politeness when doing multi-page work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0 ‚Äî Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 ‚Äî Choose 5 policy/security-help URLs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://www.mozilla.org/en-US/privacy/\",\n",
        "    \"https://www.nist.gov/privacy-framework\",\n",
        "    \"https://support.google.com/accounts/answer/6294825?hl=en\",\n",
        "    \"https://www.enisa.europa.eu/topics/data-protection\",\n",
        "    \"https://www.wikipedia.org/\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 ‚Äî Extract headings + cue flags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "CUE_PATTERNS = {\n",
        "    \"choices_controls\": r\"\\b(choice|choices|control|opt\\s?-?out|preferences|settings)\\b\",\n",
        "    \"consent\": r\"\\b(consent|agree|manage consent)\\b\",\n",
        "    \"cookies\": r\"\\b(cookie|tracking|pixels)\\b\",\n",
        "    \"sharing_third_party\": r\"\\b(third\\s?-?party|share|sharing|partners)\\b\",\n",
        "    \"retention\": r\"\\b(retention|retain|stored|storage period)\\b\",\n",
        "    \"security\": r\"\\b(security|protect|encryption|safeguards)\\b\",\n",
        "}\n",
        "\n",
        "def extract_headings(soup: BeautifulSoup) -> list[str]:\n",
        "    return [\n",
        "        t.get_text(\" \", strip=True)\n",
        "        for t in soup.find_all([\"h1\",\"h2\",\"h3\"])\n",
        "        if t.get_text(\" \", strip=True)\n",
        "    ]\n",
        "\n",
        "def score_cues(text: str) -> dict:\n",
        "    return {k: bool(re.search(p, text, re.I)) for k, p in CUE_PATTERNS.items()}\n",
        "\n",
        "def analyze(url: str) -> dict:\n",
        "    r = requests.get(url, timeout=20)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "    headings = extract_headings(soup)\n",
        "    text = soup.get_text(\" \", strip=True)\n",
        "    row = {\n",
        "        \"url\": url,\n",
        "        \"status\": r.status_code,\n",
        "        \"title\": soup.title.get_text(strip=True) if soup.title else None,\n",
        "        \"num_headings\": len(headings),\n",
        "        \"headings_preview\": headings[:12],\n",
        "    }\n",
        "    row.update(score_cues(text))\n",
        "    return row"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üß† Concept: List of Dictionaries = A Dataset\n",
        "\n",
        "If a **Dictionary** is a Row...\n",
        "And a **List** is a container...\n",
        "Then a **List of Dictionaries** is a **Table**!\n",
        "\n",
        "```python\n",
        "dataset = [\n",
        "  {\"url\": \"google.com\", \"status\": 200},  # Row 1\n",
        "  {\"url\": \"bing.com\",   \"status\": 200},  # Row 2\n",
        "]\n",
        "```\n",
        "\n",
        "This is exactly how pandas (and Excel) thinks about data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "for u in urls:\n",
        "    try:\n",
        "        rows.append(analyze(u))\n",
        "    except Exception as e:\n",
        "        rows.append({\"url\": u, \"error\": str(e)})\n",
        "rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection: headings as navigational UX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Which headings looked most ‚Äúactionable‚Äù for users?\n",
        "- Did you see ‚ÄúYour choices‚Äù / ‚Äúcontrols‚Äù / ‚Äúopt out‚Äù type structure?\n",
        "- What does this suggest about usability/comprehension?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "title": "Week 02 Assignment ‚Äî Extracting Structure: Headings, Sections, and ‚ÄúChoice‚Äù Cues"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}