{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 10 \u2014 Functional Pipelines + Testing Basics\n",
        "\n",
        "**Time budget:** ~2 hours  \n",
        "**Goal:** Build transformation pipelines (map/filter) and write a few unit tests for parser functions.\n",
        "\n",
        "**Theme (PhD focus):** Human factors of privacy & security \u2014 scraping public pages (privacy policies, cookie notices, security help pages, standards/regulator guidance) and extracting *UX-relevant* signals.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Responsible scraping note (important)\n",
        "We will only scrape **public pages** and keep the volume small.\n",
        "- Prefer a few pages, not thousands\n",
        "- Respect robots.txt/Terms of Service when you scale later\n",
        "- Avoid collecting personal data\n",
        "- Add delays for politeness when doing multi-page work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Weâ€™ll use `requests` + `BeautifulSoup`. Install if needed:\n",
        "\n",
        "```bash\n",
        "pip install requests beautifulsoup4 pandas matplotlib\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functional pipelines + testing mindset\n",
        "Weâ€™ll:\n",
        "- separate parsing from fetching (pure functions are testable)\n",
        "- map URLs \u2192 rows\n",
        "- write simple tests (assertions) for parser helpers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ§  Concept: Pure Functions (The Math Machine)\n",
        "\n",
        "A **Pure Function** is like `2 + 2`. It ALWAYS equals `4`.\n",
        "- **Impures**: `fetch_url()` (depends on internet).\n",
        "- **Pure**: `parse_html()` (depends ONLY on the HTML you give it).\n",
        "\n",
        "**Why care?**\n",
        "You can test Pure Functions without the internet. This is called **Unit Testing**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ§  Concept: Unit Tests (The Safety Net)\n",
        "\n",
        "Code: `assert result == expected`\n",
        "\n",
        "It's a robotic checklist.\n",
        "- *\"Did the parser find the 'Opt Out' button? Yes/No.\"*\n",
        "- If `False`, the robot yells (Error).\n",
        "- You run this **every time you save** to make sure you didn't break anything."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_cues(text: str) -> dict:\n",
        "    return {\n",
        "        \"choices_controls\": bool(re.search(r\"\\b(opt\\s?-?out|preferences|your choices|controls?)\\b\", text, re.I)),\n",
        "        \"retention\": bool(re.search(r\"\\b(retention|retain)\\b\", text, re.I)),\n",
        "    }\n",
        "\n",
        "def test_parse_cues():\n",
        "    t = \"You can opt out in settings. We retain data for 30 days.\"\n",
        "    cues = parse_cues(t)\n",
        "    assert cues[\"choices_controls\"] is True\n",
        "    assert cues[\"retention\"] is True\n",
        "\n",
        "test_parse_cues()\n",
        "print(\"Tests passed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://www.mozilla.org/en-US/privacy/\",\n",
        "    \"https://www.nist.gov/privacy-framework\",\n",
        "]\n",
        "\n",
        "def fetch_text(url: str) -> str:\n",
        "    r = requests.get(url, timeout=20)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "    return soup.get_text(\" \", strip=True)\n",
        "\n",
        "rows = [{\"url\": u, **parse_cues(fetch_text(u))} for u in urls]\n",
        "pd.DataFrame(rows)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "title": "Week 10 Concepts â€” Functional Pipelines + Testing Basics"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}