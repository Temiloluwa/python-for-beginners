{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 12 \u2014 LLM Enrichment (Gemini/OpenAI) for Policy UX Coding\n",
        "\n",
        "**Time budget:** ~2 hours  \n",
        "**Goal:** Use an LLM to label/summary/classify policy sections; store enriched outputs safely.\n",
        "\n",
        "**Theme (PhD focus):** Human factors of privacy & security \u2014 scraping public pages (privacy policies, cookie notices, security help pages, standards/regulator guidance) and extracting *UX-relevant* signals.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverables\n",
        "- A completed notebook with working code\n",
        "- A dataset variable (`rows` or `df`) saved to disk (CSV/JSON depending on week)\n",
        "- 3\u20135 bullet reflection grounded in human factors/privacy-security research\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Responsible scraping note (important)\n",
        "We will only scrape **public pages** and keep the volume small.\n",
        "- Prefer a few pages, not thousands\n",
        "- Respect robots.txt/Terms of Service when you scale later\n",
        "- Avoid collecting personal data\n",
        "- Add delays for politeness when doing multi-page work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0 \u2014 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 \u2014 Choose 5 short excerpts from your scraped pages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Paste excerpts (100\u2013300 words each) below. Keep it small."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "excerpts = [\n",
        "    \"\"\"PASTE EXCERPT 1\"\"\",\n",
        "    \"\"\"PASTE EXCERPT 2\"\"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 \u2014 Implement an LLM call (Gemini/OpenAI) OR use the placeholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def llm_label_section(text: str) -> dict:\n",
        "    # TODO: replace with real API call\n",
        "    labels = {\n",
        "        \"choices_controls\": bool(re.search(r\"\\b(opt\\s?-?out|preferences|your choices|controls?)\\b\", text, re.I)),\n",
        "        \"retention\": bool(re.search(r\"\\b(retention|retain)\\b\", text, re.I)),\n",
        "        \"third_party\": bool(re.search(r\"\\b(third\\s?-?party|share|sharing)\\b\", text, re.I)),\n",
        "        \"security\": bool(re.search(r\"\\b(encrypt|encryption|security|safeguards)\\b\", text, re.I)),\n",
        "    }\n",
        "    return {\"labels\": labels, \"summary\": text[:200] + (\"...\" if len(text) > 200 else \"\")}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "enriched = [llm_label_section(x) for x in excerpts]\n",
        "enriched"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 \u2014 Save enriched outputs with provenance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone\n",
        "payload = {\n",
        "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
        "    \"model\": \"placeholder-or-your-model-name\",\n",
        "    \"items\": [{\"text\": t, \"enriched\": e} for t, e in zip(excerpts, enriched)],\n",
        "}\n",
        "Path(\"week12_enriched.json\").write_text(json.dumps(payload, indent=2), encoding=\"utf-8\")\n",
        "print(\"Saved week12_enriched.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- What did the LLM help with (coding, summarization, classification)?\n",
        "- What are the risks (hallucination, bias) and how would you validate?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "title": "Week 12 Assignment \u2014 LLM Enrichment (Gemini/OpenAI) for Policy UX Coding"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}