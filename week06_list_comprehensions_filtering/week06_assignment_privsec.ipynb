{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 06 \u2014 Text Signals for Human Factors: Readability + Sentiment (light)\n",
        "\n",
        "**Time budget:** ~2 hours  \n",
        "**Goal:** Compute basic text metrics (length, readability approximation) and visualize distributions.\n",
        "\n",
        "**Theme (PhD focus):** Human factors of privacy & security \u2014 scraping public pages (privacy policies, cookie notices, security help pages, standards/regulator guidance) and extracting *UX-relevant* signals.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverables\n",
        "- A completed notebook with working code\n",
        "- A dataset variable (`rows` or `df`) saved to disk (CSV/JSON depending on week)\n",
        "- 3\u20135 bullet reflection grounded in human factors/privacy-security research\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Responsible scraping note (important)\n",
        "We will only scrape **public pages** and keep the volume small.\n",
        "- Prefer a few pages, not thousands\n",
        "- Respect robots.txt/Terms of Service when you scale later\n",
        "- Avoid collecting personal data\n",
        "- Add delays for politeness when doing multi-page work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0 \u2014 Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 \u2014 Scrape text + compute metrics for 3\u20135 pages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def basic_text_metrics(text: str) -> dict:\n",
        "    words = text.split()\n",
        "    num_words = len(words)\n",
        "    sentences = re.split(r\"[.!?]+\\s+\", text)\n",
        "    sentences = [s for s in sentences if s.strip()]\n",
        "    avg_sentence_len = (num_words / len(sentences)) if sentences else None\n",
        "    return {\"num_words\": num_words, \"num_sentences\": len(sentences), \"avg_sentence_len\": avg_sentence_len}\n",
        "\n",
        "def scrape_text_metrics(url: str) -> dict:\n",
        "    r = requests.get(url, timeout=20)\n",
        "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "    text = soup.get_text(\" \", strip=True)\n",
        "    row = {\"url\": url, \"status\": r.status_code}\n",
        "    row.update(basic_text_metrics(text))\n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "urls = [\n",
        "    \"https://www.mozilla.org/en-US/privacy/\",\n",
        "    \"https://www.nist.gov/privacy-framework\",\n",
        "]\n",
        "rows = [scrape_text_metrics(u) for u in urls]\n",
        "df = pd.DataFrame(rows)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\"num_words\"].plot(kind=\"bar\", title=\"Word count by page\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection: readability as a UX issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Does length correlate with comprehensibility?\n",
        "- What other measures would you want (Flesch, jargon count, etc.)?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "title": "Week 06 Assignment \u2014 Text Signals for Human Factors: Readability + Sentiment (light)"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}