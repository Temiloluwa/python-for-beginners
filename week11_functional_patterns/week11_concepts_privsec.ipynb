{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 11 \u2014 More Complex Sites: Sitemaps + Multi-source Datasets\n",
        "\n",
        "**Time budget:** ~2 hours  \n",
        "**Goal:** Use sitemap.xml (where available) or curated sources; unify multi-source datasets.\n",
        "\n",
        "**Theme (PhD focus):** Human factors of privacy & security \u2014 scraping public pages (privacy policies, cookie notices, security help pages, standards/regulator guidance) and extracting *UX-relevant* signals.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Responsible scraping note (important)\n",
        "We will only scrape **public pages** and keep the volume small.\n",
        "- Prefer a few pages, not thousands\n",
        "- Respect robots.txt/Terms of Service when you scale later\n",
        "- Avoid collecting personal data\n",
        "- Add delays for politeness when doing multi-page work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "Weâ€™ll use `requests` + `BeautifulSoup`. Install if needed:\n",
        "\n",
        "```bash\n",
        "pip install requests beautifulsoup4 pandas matplotlib\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sitemaps + multi-source datasets\n",
        "Many sites expose `sitemap.xml`. If available, it can help you discover relevant pages.\n",
        "We will keep this lightweight and ethical: extract a *small* subset of URLs.\n",
        "\n",
        "If a site has no sitemap, fall back to a curated list.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ§  Concept: Scraping vs. Crawling\n",
        "\n",
        "| Activity | Definition | Analogy |\n",
        "| :--- | :--- | :--- |\n",
        "| **Scraping** | Extracting data from a specific page. | Reading a book and taking notes. |\n",
        "| **Crawling** | Finding new URLs to read. | Walking through the library to *find* books. |\n",
        "\n",
        "**Sitemaps** are the Library Catalog. They list every book (page) so you don't have to wander around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def try_fetch_sitemap(base_url: str) -> list[str]:\n",
        "    # naive: base_url like https://example.com\n",
        "    sitemap_url = base_url.rstrip(\"/\") + \"/sitemap.xml\"\n",
        "    r = requests.get(sitemap_url, timeout=20, headers={\"User-Agent\":\"HF-PrivacyScraper/0.1\"})\n",
        "    if r.status_code != 200:\n",
        "        return []\n",
        "    soup = BeautifulSoup(r.text, \"xml\")\n",
        "    locs = [loc.get_text(strip=True) for loc in soup.find_all(\"loc\")]\n",
        "    return locs\n",
        "\n",
        "# Example (may or may not exist):\n",
        "try_fetch_sitemap(\"https://www.mozilla.org\")[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Unifying sources\n",
        "Add a `source` field and a common schema so you can compare across institutions.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "title": "Week 11 Concepts â€” More Complex Sites: Sitemaps + Multi-source Datasets"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}