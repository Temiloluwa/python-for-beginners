{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 04 â€” Data Formats: CSV vs JSON + Clean Schemas\n",
        "\n",
        "**Time budget:** ~2 hours  \n",
        "**Goal:** Design a simple schema and export/import clean datasets; basic validation.\n",
        "\n",
        "**Theme (PhD focus):** Human factors of privacy & security \u2014 scraping public pages (privacy policies, cookie notices, security help pages, standards/regulator guidance) and extracting *UX-relevant* signals.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Deliverables\n",
        "- A completed notebook with working code\n",
        "- A dataset variable (`rows` or `df`) saved to disk (CSV/JSON depending on week)\n",
        "- 3\u20135 bullet reflection grounded in human factors/privacy-security research\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Responsible scraping note (important)\n",
        "We will only scrape **public pages** and keep the volume small.\n",
        "- Prefer a few pages, not thousands\n",
        "- Respect robots.txt/Terms of Service when you scale later\n",
        "- Avoid collecting personal data\n",
        "- Add delays for politeness when doing multi-page work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 0 â€” Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "import time\n",
        "import json\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 â€” Start from your Week 2 or Week 3 `rows`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = [\n",
        "    # paste your rows here or re-run your scraper from prior weeks\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 â€” Export JSON (nested-friendly) and CSV (flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ðŸ§  Pro Tip: `pathlib` for File Paths\n",
        "\n",
        "Instead of:\n",
        "```python\n",
        "open(\"data/file.txt\", \"w\").write(\"hello\")\n",
        "```\n",
        "We use:\n",
        "```python\n",
        "from pathlib import Path\n",
        "Path(\"data/file.txt\").write_text(\"hello\", encoding=\"utf-8\")\n",
        "```\n",
        "It handles Mac/Windows path differences (`/` vs `\\`) automatically!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "def to_json(path: str, rows: list[dict]) -> None:\n",
        "    Path(path).write_text(json.dumps(rows, indent=2), encoding=\"utf-8\")\n",
        "\n",
        "def to_csv_flat(path: str, rows: list[dict], fieldnames: list[str]) -> None:\n",
        "    with open(path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        w = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        w.writeheader()\n",
        "        for r in rows:\n",
        "            w.writerow({k: r.get(k) for k in fieldnames})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: choose a minimal set of CSV fields you care about\n",
        "fieldnames = [\"url\", \"status\", \"num_headings\"]  # example\n",
        "to_json(\"week04_rows.json\", rows)\n",
        "to_csv_flat(\"week04_rows.csv\", rows, fieldnames=fieldnames)\n",
        "print(\"Saved week04_rows.json and week04_rows.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reflection: schema decisions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- What did you lose when converting to CSV?\n",
        "- Which format fits your research workflow better and why?\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    },
    "title": "Week 04 Assignment â€” Data Formats: CSV vs JSON + Clean Schemas"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}